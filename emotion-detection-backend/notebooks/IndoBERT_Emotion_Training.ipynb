{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üáÆüá© IndoBERT Emotion Detection Training\n",
                "\n",
                "Notebook ini untuk melatih model deteksi emosi bahasa Indonesia menggunakan IndoBERT.\n",
                "\n",
                "**Langkah:**\n",
                "1. Upload dataset (train.txt, val.txt, test.txt)\n",
                "2. Jalankan semua cell\n",
                "3. Download model yang sudah dilatih\n",
                "\n",
                "**Pastikan GPU aktif:** Runtime ‚Üí Change runtime type ‚Üí GPU"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q transformers torch accelerate sentencepiece scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Check GPU\n",
                "import torch\n",
                "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ],
            "metadata": {
                "id": "check_gpu"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Upload dataset files\n",
                "from google.colab import files\n",
                "print(\"Upload train.txt, val.txt, dan test.txt\")\n",
                "uploaded = files.upload()"
            ],
            "metadata": {
                "id": "upload"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "import re\n",
                "import pickle\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
                "import torch\n",
                "from torch.utils.data import Dataset\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    TrainingArguments,\n",
                "    Trainer,\n",
                "    EarlyStoppingCallback\n",
                ")\n",
                "\n",
                "# Config\n",
                "MODEL_NAME = \"indobenchmark/indobert-base-p1\"\n",
                "MAX_LEN = 128\n",
                "BATCH_SIZE = 16\n",
                "EPOCHS = 5\n",
                "LEARNING_RATE = 2e-5\n",
                "\n",
                "print(\"‚úÖ Imports done!\")"
            ],
            "metadata": {
                "id": "imports"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def preprocess_text(text):\n",
                "    \"\"\"Simple text cleaning.\"\"\"\n",
                "    if not text or not isinstance(text, str):\n",
                "        return \"\"\n",
                "    text = text.lower()\n",
                "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
                "    text = re.sub(r'@\\w+', '', text)\n",
                "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
                "    text = re.sub(r'\\brt\\b', '', text)\n",
                "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
                "    text = re.sub(r'\\s+', ' ', text)\n",
                "    return text.strip()\n",
                "\n",
                "def load_data(filepath):\n",
                "    \"\"\"Load and preprocess data.\"\"\"\n",
                "    df = pd.read_csv(filepath, sep=';', header=None, names=['text', 'label'])\n",
                "    df = df.dropna()\n",
                "    df['text'] = df['text'].apply(preprocess_text)\n",
                "    df = df[df['text'].str.len() > 0]\n",
                "    return df\n",
                "\n",
                "# Load data\n",
                "print(\"üìÇ Loading dataset...\")\n",
                "train_df = load_data('train.txt')\n",
                "val_df = load_data('val.txt')\n",
                "test_df = load_data('test.txt')\n",
                "\n",
                "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
                "print(f\"\\nDistribution:\\n{train_df['label'].value_counts()}\")"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Encode labels\n",
                "label_encoder = LabelEncoder()\n",
                "train_labels = label_encoder.fit_transform(train_df['label'])\n",
                "val_labels = label_encoder.transform(val_df['label'])\n",
                "test_labels = label_encoder.transform(test_df['label'])\n",
                "\n",
                "num_classes = len(label_encoder.classes_)\n",
                "print(f\"Classes ({num_classes}): {list(label_encoder.classes_)}\")"
            ],
            "metadata": {
                "id": "encode_labels"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "class EmotionDataset(Dataset):\n",
                "    def __init__(self, texts, labels, tokenizer, max_len):\n",
                "        self.texts = texts\n",
                "        self.labels = labels\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_len = max_len\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.texts)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        text = str(self.texts[idx])\n",
                "        label = self.labels[idx]\n",
                "\n",
                "        encoding = self.tokenizer(\n",
                "            text,\n",
                "            add_special_tokens=True,\n",
                "            max_length=self.max_len,\n",
                "            padding='max_length',\n",
                "            truncation=True,\n",
                "            return_attention_mask=True,\n",
                "            return_tensors='pt'\n",
                "        )\n",
                "\n",
                "        return {\n",
                "            'input_ids': encoding['input_ids'].flatten(),\n",
                "            'attention_mask': encoding['attention_mask'].flatten(),\n",
                "            'labels': torch.tensor(label, dtype=torch.long)\n",
                "        }\n",
                "\n",
                "print(\"‚úÖ Dataset class defined!\")"
            ],
            "metadata": {
                "id": "dataset_class"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Load tokenizer and model\n",
                "print(f\"üìù Loading tokenizer: {MODEL_NAME}\")\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "\n",
                "print(f\"üèóÔ∏è Loading model: {MODEL_NAME}\")\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    num_labels=num_classes,\n",
                "    id2label={i: label for i, label in enumerate(label_encoder.classes_)},\n",
                "    label2id={label: i for i, label in enumerate(label_encoder.classes_)}\n",
                ")\n",
                "\n",
                "# Move to GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model.to(device)\n",
                "print(f\"‚úÖ Model loaded on {device}!\")"
            ],
            "metadata": {
                "id": "load_model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Create datasets\n",
                "train_dataset = EmotionDataset(train_df['text'].values, train_labels, tokenizer, MAX_LEN)\n",
                "val_dataset = EmotionDataset(val_df['text'].values, val_labels, tokenizer, MAX_LEN)\n",
                "test_dataset = EmotionDataset(test_df['text'].values, test_labels, tokenizer, MAX_LEN)\n",
                "\n",
                "print(f\"‚úÖ Datasets created!\")"
            ],
            "metadata": {
                "id": "create_datasets"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "def compute_metrics(eval_pred):\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    accuracy = accuracy_score(labels, predictions)\n",
                "    f1 = f1_score(labels, predictions, average='weighted')\n",
                "    return {'accuracy': accuracy, 'f1': f1}\n",
                "\n",
                "# Training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='./results',\n",
                "    num_train_epochs=EPOCHS,\n",
                "    per_device_train_batch_size=BATCH_SIZE,\n",
                "    per_device_eval_batch_size=BATCH_SIZE,\n",
                "    warmup_steps=500,\n",
                "    weight_decay=0.01,\n",
                "    logging_dir='./logs',\n",
                "    logging_steps=50,\n",
                "    eval_strategy='epoch',\n",
                "    save_strategy='epoch',\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model='accuracy',\n",
                "    greater_is_better=True,\n",
                "    report_to='none',\n",
                "    learning_rate=LEARNING_RATE,\n",
                ")\n",
                "\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_dataset,\n",
                "    eval_dataset=val_dataset,\n",
                "    compute_metrics=compute_metrics,\n",
                "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Trainer ready!\")"
            ],
            "metadata": {
                "id": "trainer"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Train!\n",
                "print(\"üöÄ Training...\")\n",
                "trainer.train()"
            ],
            "metadata": {
                "id": "train"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Evaluate\n",
                "print(\"üìà Evaluating on test set...\")\n",
                "test_results = trainer.evaluate(test_dataset)\n",
                "print(f\"\\n‚úÖ Test Accuracy: {test_results['eval_accuracy']*100:.2f}%\")\n",
                "print(f\"‚úÖ Test F1: {test_results['eval_f1']*100:.2f}%\")"
            ],
            "metadata": {
                "id": "evaluate"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Detailed classification report\n",
                "predictions = trainer.predict(test_dataset)\n",
                "preds = np.argmax(predictions.predictions, axis=1)\n",
                "print(\"\\nüìä Classification Report:\")\n",
                "print(classification_report(test_labels, preds, target_names=label_encoder.classes_))"
            ],
            "metadata": {
                "id": "report"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Save model\n",
                "print(\"üíæ Saving model...\")\n",
                "os.makedirs('indobert_emotion', exist_ok=True)\n",
                "model.save_pretrained('indobert_emotion/model')\n",
                "tokenizer.save_pretrained('indobert_emotion/tokenizer')\n",
                "\n",
                "with open('indobert_emotion/label_encoder.pkl', 'wb') as f:\n",
                "    pickle.dump(label_encoder, f)\n",
                "\n",
                "print(\"‚úÖ Model saved!\")"
            ],
            "metadata": {
                "id": "save"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Test prediction\n",
                "def predict_emotion(text):\n",
                "    model.eval()\n",
                "    encoding = tokenizer(\n",
                "        preprocess_text(text),\n",
                "        add_special_tokens=True,\n",
                "        max_length=MAX_LEN,\n",
                "        padding='max_length',\n",
                "        truncation=True,\n",
                "        return_tensors='pt'\n",
                "    )\n",
                "    input_ids = encoding['input_ids'].to(device)\n",
                "    attention_mask = encoding['attention_mask'].to(device)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
                "        probs = torch.softmax(outputs.logits, dim=1)\n",
                "        pred = torch.argmax(probs, dim=1).item()\n",
                "        conf = probs[0][pred].item()\n",
                "\n",
                "    emotion = label_encoder.inverse_transform([pred])[0]\n",
                "    return emotion, conf\n",
                "\n",
                "# Test samples\n",
                "test_texts = [\n",
                "    \"Senang banget hari ini!\",\n",
                "    \"Sedih sekali dia pergi\",\n",
                "    \"Marah aku sama kamu!\",\n",
                "    \"Takut dengan keadaan ini\",\n",
                "    \"Aku cinta kamu\",\n",
                "    \"Hari ini biasa saja\"\n",
                "]\n",
                "\n",
                "print(\"\\nüß™ Test Predictions:\")\n",
                "print(\"=\"*50)\n",
                "for text in test_texts:\n",
                "    emotion, conf = predict_emotion(text)\n",
                "    print(f'\"{text}\"')\n",
                "    print(f\"  ‚Üí {emotion} ({conf*100:.1f}%)\")\n",
                "    print()"
            ],
            "metadata": {
                "id": "test_predict"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Download model\n",
                "!zip -r indobert_emotion.zip indobert_emotion/\n",
                "files.download('indobert_emotion.zip')\n",
                "print(\"\\n‚úÖ Download started! Extract zip dan letakkan di folder saved_models_indobert\")"
            ],
            "metadata": {
                "id": "download"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}